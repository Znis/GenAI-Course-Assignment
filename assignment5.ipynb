{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1496,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents.format_scratchpad.openai_tools import format_to_openai_tool_messages\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents import tool\n",
    "from langchain_community.tools.google_jobs import GoogleJobsQueryRun\n",
    "from langchain_community.utilities.google_jobs import GoogleJobsAPIWrapper\n",
    "from langchain.schema.runnable import RunnableMap\n",
    "from langchain.schema import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1497,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\" # enables the tracing\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"assignment-5\" #project name in the LangSmith platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1498,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1499,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather_data(city: str) -> str:\n",
    "    \"\"\"Calls the Weather API and return the weather data\n",
    "    Args:\n",
    "        city: str\n",
    "    Returns:\n",
    "        str\n",
    "    \"\"\"\n",
    "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={os.getenv('WEATHER_API_KEY')}&units=metric\"\n",
    "    response = requests.get(url)\n",
    "    return str(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1500,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [ get_weather_data ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1501,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are very powerful weather data assistant equipped with multiple tools.\n",
    "              Here is the detailed instruction:\n",
    "              1. Call the Weather API to get the weather data of the city.\n",
    "              2. If the Weather API returns valid response with weather data then, return the weather data in given output format.\n",
    "              3. If the Weather API returns no weather data then, return the response saying the weather data is not available.\n",
    "              The desired output format for different scenarios are given below:\n",
    "              Here is the weather data of the city <city_name>:\n",
    "              <weather_data_in_bullet_form (dash separated)>\n",
    "              \"\"\",\n",
    "\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"), # sequence of messages that contain the previous agent tool invocations and the corresponding tool outputs\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1502,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1503,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1504,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1505,
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_prompt_template = \"\"\"You are a funny assistant.\n",
    " You will provide one short and funny jokes on the given topic.\n",
    "If the topic is not specified then, you can give your own jokes.\n",
    "{input}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1506,
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_prompt = ChatPromptTemplate.from_template(joke_prompt_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1507,
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_prompt_chain = joke_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1508,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_jobs_tool = GoogleJobsQueryRun(api_wrapper=GoogleJobsAPIWrapper(serp_api_key=os.getenv('SERPAPI_API_KEY')), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1509,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_jobs_chain = (lambda x: x['input']) | google_jobs_tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1510,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_template = \"\"\"\n",
    "Determine the category of the following text into one of these three categories\n",
    "and respond with the category only.\n",
    "1. Weather\n",
    "2. Joke\n",
    "3. Job\n",
    "If the question is not related to one of the categories,\n",
    "respond with \"Other\".\n",
    "Here is an example:\n",
    "###\n",
    "Question: What is the weather in XYZ city?\n",
    "Weather\n",
    "###\n",
    "\n",
    "Question: {question}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1511,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = ChatPromptTemplate.from_template(system_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1512,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt_template = \"\"\"\n",
    "Respond politely saying you can not answer the current question and only to ask question within the categories of Weather, Joke or Job.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1513,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = ChatPromptTemplate.from_template(base_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1514,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_chain = base_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1515,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_chain(output):\n",
    "    if output[\"action\"] == \"Weather\":\n",
    "        return weather_agent_executor \n",
    "    elif output[\"action\"] == \"Job\":\n",
    "        return google_jobs_chain\n",
    "    elif output[\"action\"] == \"Joke\":\n",
    "        return joke_prompt | llm | StrOutputParser()\n",
    "    else:\n",
    "        return base_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1516,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_chain = system_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I can only answer questions within the categories of Weather, Joke, or Job. Do you have a question in one of those categories that I can help with?\n"
     ]
    }
   ],
   "source": [
    "chain = RunnableMap({\n",
    "    \"action\": router_chain,\n",
    "    \"input\": lambda x: x[\"question\"]\n",
    "})| select_chain\n",
    "\n",
    "output = chain.invoke({\"question\":\"Tell me a joke and weather in kathmandu\"})\n",
    "print(output if isinstance(output, str) else output[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1518,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1519,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains_infos= [\n",
    "    {\n",
    "        'name': 'weather',\n",
    "        'description': 'Provides the current weather data for a given city name using the weather agent.',\n",
    "    },\n",
    "    {\n",
    "        'name': 'job',\n",
    "        'description': 'Fetches job listings using the Google Jobs tool within Langchain based on given criteria.',\n",
    "    },\n",
    "    {\n",
    "        'name': 'joke',\n",
    "        'description': 'Generates a joke using a simple prompt chain for humor.',\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1520,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "destination_chains['weather'] = weather_agent_executor\n",
    "destination_chains['job'] = google_jobs_chain\n",
    "destination_chains['joke'] = joke_prompt_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1521,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from typing import Literal\n",
    "from typing_extensions import TypedDict\n",
    "class RouteQuery(TypedDict):\n",
    "    \"\"\"Route query to destination.\"\"\"\n",
    "    destination: Literal[\"weather\", \"job\", \"joke\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1522,
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations = [f\"{chain['name']}: {chain['description']}\" for chain in chains_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = ChatPromptTemplate.from_template(template=router_template)\n",
    "router_chain = router_chain | llm.with_structured_output(RouteQuery) | itemgetter(\"destination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1523,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = {\n",
    "    \"destination\": router_chain,\n",
    "    \"question\": lambda x: x[\"question\"],\n",
    "    \"input\": lambda x: x[\"question\"],\n",
    "} | RunnableLambda(\n",
    "lambda x: destination_chains['weather'] if x[\"destination\"] == \"weather\" \n",
    "         else destination_chains['joke'] if x[\"destination\"] == \"joke\" \n",
    "         else destination_chains['job'] if x[\"destination\"] == \"job\" \n",
    "         else base_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the scarecrow win an award?\n",
      "Because he was outstanding in his field!\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"question\":\"tell me the joke\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-assignment-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
