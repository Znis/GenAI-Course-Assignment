{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Getting started with Generative-AI </b>\n",
    "Submitted By: <b><i>Jenish Twayana</i></b>  \n",
    "\n",
    "Submitted Date: <b><i>9th September, 2024</i></b>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Realm of Router Chains\n",
    "You are tasked with building a multi-function system using LangChain that handles three\n",
    "different types of user inputs:  \n",
    "\n",
    "1. Weather Inquiries: Users ask about the current weather or weather forecasts.  \n",
    "2. Job Queries: Users request queries on job openings and things  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <b>Objective:</b>    \n",
    "\n",
    "1. Create a Router Chain that correctly routes these different types of inputs to the\n",
    "appropriate sub-chains. Implement each sub-chain and integrate them into the Router\n",
    "Chain.\n",
    "2. Create a diagram illustrating how you connected the chains. You can hand-draw this\n",
    "diagram.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Specific Instructions:</b>   \n",
    "\n",
    "● Weather Inquiries  \n",
    "○ To handle weather inquiries, utilize custom agents/tools designed for weather\n",
    "information retrieval. Users can request the weather for any city.  \n",
    "● Job Queries  \n",
    "○ For job-related queries, employ the built-in tools available on langchain.  \n",
    "○ Hint: You can use the \"google-jobs\" tool to find job listings and relevant\n",
    "information.  \n",
    "● Joke Requests  \n",
    "○ For joke requests, apply prompt engineering techniques, principles or guidelines\n",
    "to generate jokes directly.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1496,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents.format_scratchpad.openai_tools import format_to_openai_tool_messages\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents import tool\n",
    "from langchain_community.tools.google_jobs import GoogleJobsQueryRun\n",
    "from langchain_community.utilities.google_jobs import GoogleJobsAPIWrapper\n",
    "from langchain.schema.runnable import RunnableMap\n",
    "from langchain.schema import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment variables for LangChain Tracing\n",
    "It logs the tracing data in the LangSmith web interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1497,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\" # enables the tracing\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"assignment-5\" #project name in the LangSmith platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1498,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating the Weather Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Tool for fetching Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1499,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather_data(city: str) -> str:\n",
    "    \"\"\"Calls the Weather API and return the weather data\n",
    "    Args:\n",
    "        city: str\n",
    "    Returns:\n",
    "        str\n",
    "    \"\"\"\n",
    "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={os.getenv('WEATHER_API_KEY')}&units=metric\"\n",
    "    response = requests.get(url)\n",
    "    return str(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1500,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [ get_weather_data ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1501,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are very powerful weather data assistant equipped with multiple tools.\n",
    "              Here is the detailed instruction:\n",
    "              1. Call the Weather API to get the weather data of the city.\n",
    "              2. If the Weather API returns valid response with weather data then, return the weather data in given output format.\n",
    "              3. If the Weather API returns no weather data then, return the response saying the weather data is not available.\n",
    "              The desired output format for different scenarios are given below:\n",
    "              Here is the weather data of the city <city_name>:\n",
    "              <weather_data_in_bullet_form (dash separated)>\n",
    "              \"\"\",\n",
    "\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"), # sequence of messages that contain the previous agent tool invocations and the corresponding tool outputs\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bind the Custom tools to the Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1502,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1503,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1504,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Prompt chain for Jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1505,
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_prompt_template = \"\"\"You are a funny assistant.\n",
    " You will provide one short and funny jokes on the given topic.\n",
    "If the topic is not specified then, you can give your own jokes.\n",
    "{input}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1506,
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_prompt = ChatPromptTemplate.from_template(joke_prompt_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1507,
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_prompt_chain = joke_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating Tool chain for Google Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1508,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_jobs_tool = GoogleJobsQueryRun(api_wrapper=GoogleJobsAPIWrapper(serp_api_key=os.getenv('SERPAPI_API_KEY')), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1509,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_jobs_chain = (lambda x: x['input']) | google_jobs_tool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1510,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_template = \"\"\"\n",
    "Determine the category of the following text into one of these three categories\n",
    "and respond with the category only.\n",
    "1. Weather\n",
    "2. Joke\n",
    "3. Job\n",
    "If the question is not related to one of the categories,\n",
    "respond with \"Other\".\n",
    "Here is an example:\n",
    "###\n",
    "Question: What is the weather in XYZ city?\n",
    "Weather\n",
    "###\n",
    "\n",
    "Question: {question}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1511,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = ChatPromptTemplate.from_template(system_prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Prompt chain for \"Other\" categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1512,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt_template = \"\"\"\n",
    "Respond politely saying you can not answer the current question and only to ask question within the categories of Weather, Joke or Job.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1513,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = ChatPromptTemplate.from_template(base_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1514,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_chain = base_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for selecting appropriate chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1515,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_chain(output):\n",
    "    if output[\"action\"] == \"Weather\":\n",
    "        return weather_agent_executor \n",
    "    elif output[\"action\"] == \"Job\":\n",
    "        return google_jobs_chain\n",
    "    elif output[\"action\"] == \"Joke\":\n",
    "        return joke_prompt | llm | StrOutputParser()\n",
    "    else:\n",
    "        return base_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1516,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_chain = system_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I can only answer questions within the categories of Weather, Joke, or Job. Do you have a question in one of those categories that I can help with?\n"
     ]
    }
   ],
   "source": [
    "chain = RunnableMap({\n",
    "    \"action\": router_chain,\n",
    "    \"input\": lambda x: x[\"question\"]\n",
    "})| select_chain\n",
    "\n",
    "output = chain.invoke({\"question\":\"Tell me a joke and weather in kathmandu\"})\n",
    "print(output if isinstance(output, str) else output[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Approach using MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "### Almost similar to the above approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1518,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1519,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains_infos= [\n",
    "    {\n",
    "        'name': 'weather',\n",
    "        'description': 'Provides the current weather data for a given city name using the weather agent.',\n",
    "    },\n",
    "    {\n",
    "        'name': 'job',\n",
    "        'description': 'Fetches job listings using the Google Jobs tool within Langchain based on given criteria.',\n",
    "    },\n",
    "    {\n",
    "        'name': 'joke',\n",
    "        'description': 'Generates a joke using a simple prompt chain for humor.',\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Weather Agent, Google Jobs Tool chain and Joke chain in the destination_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1520,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "destination_chains['weather'] = weather_agent_executor\n",
    "destination_chains['job'] = google_jobs_chain\n",
    "destination_chains['joke'] = joke_prompt_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1521,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from typing import Literal\n",
    "from typing_extensions import TypedDict\n",
    "class RouteQuery(TypedDict):\n",
    "    \"\"\"Route query to destination.\"\"\"\n",
    "    destination: Literal[\"weather\", \"job\", \"joke\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations = [f\"{chain['name']}: {chain['description']}\" for chain in chains_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1522,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = ChatPromptTemplate.from_template(template=router_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_chain = router_prompt | llm.with_structured_output(RouteQuery) | itemgetter(\"destination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1523,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = {\n",
    "    \"destination\": router_chain,\n",
    "    \"question\": lambda x: x[\"question\"],\n",
    "    \"input\": lambda x: x[\"question\"],\n",
    "} | RunnableLambda(\n",
    "lambda x: destination_chains['weather'] if x[\"destination\"] == \"weather\" \n",
    "         else destination_chains['joke'] if x[\"destination\"] == \"joke\" \n",
    "         else destination_chains['job'] if x[\"destination\"] == \"job\" \n",
    "         else base_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the scarecrow win an award?\n",
      "Because he was outstanding in his field!\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"question\":\"tell me the joke\"}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-assignment-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
